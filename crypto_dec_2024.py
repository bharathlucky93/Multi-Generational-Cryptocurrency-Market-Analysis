# -*- coding: utf-8 -*-
"""Crypto_Dec_2024.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OFfhKh9d3JBHQAoNdTqgr-RkUBeSFvk7

##Final
"""

"""
Cryptocurrency Analysis using Machine Learning
This script is designed to run in Google Colab and analyze BTC, ETH, and SOL simultaneously
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import torch
import torch.nn as nn
from prophet import Prophet
import os
import json

# Create necessary directories
os.makedirs('/content/analysis_results/plots', exist_ok=True)
os.makedirs('/content/analysis_results/data', exist_ok=True)

def load_data():
    """Load the prepared data files"""
    try:
        price_volume_df = pd.read_csv('/content/price_volume_data.csv')
        returns_df = pd.read_csv('/content/returns_data.csv')
        technical_df = pd.read_csv('/content/technical_data.csv')

        # Convert timestamp columns to datetime
        price_volume_df['timestamp'] = pd.to_datetime(price_volume_df['timestamp'])
        returns_df['date'] = pd.to_datetime(returns_df['date'])
        technical_df['date'] = pd.to_datetime(technical_df['date'])

        return price_volume_df, returns_df, technical_df
    except Exception as e:
        print(f"Error loading data: {str(e)}")
        return None, None, None

class MultivariateLSTM(nn.Module):
    def __init__(self, input_size=3, hidden_layer_size=64, output_size=3):
        super().__init__()
        self.hidden_layer_size = hidden_layer_size
        self.lstm = nn.LSTM(input_size, hidden_layer_size, batch_first=True)
        self.linear = nn.Linear(hidden_layer_size, output_size)

    def forward(self, x):
        lstm_out, _ = self.lstm(x)
        predictions = self.linear(lstm_out[:, -1, :])
        return predictions

def calculate_metrics(y_true, y_pred):
    """Calculate various evaluation metrics"""
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100

    return {
        'MSE': mse,
        'RMSE': rmse,
        'MAE': mae,
        'R2': r2,
        'MAPE': mape
    }

def prepare_multivariate_lstm_data(data, lookback):
    """Prepare multivariate data for LSTM model"""
    X, y = [], []
    for i in range(len(data)-lookback):
        sequence = data[i:(i+lookback)]
        target = data[i+lookback]
        X.append(sequence)
        y.append(target)
    return np.array(X), np.array(y)

def train_multivariate_lstm(price_data, coin_columns, lookback=30, epochs=100):
    """Train LSTM model for multiple cryptocurrencies"""
    # Scale the data
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(price_data[coin_columns])

    # Prepare sequences
    X, y = prepare_multivariate_lstm_data(scaled_data, lookback)

    # Split data
    train_size = int(len(X) * 0.8)
    X_train = X[:train_size]
    y_train = y[:train_size]
    X_test = X[train_size:]
    y_test = y[train_size:]

    # Convert to PyTorch tensors
    X_train = torch.FloatTensor(X_train)
    y_train = torch.FloatTensor(y_train)
    X_test = torch.FloatTensor(X_test)
    y_test = torch.FloatTensor(y_test)

    # Initialize model
    model = MultivariateLSTM(input_size=len(coin_columns), hidden_layer_size=64, output_size=len(coin_columns))
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

    # Training loop
    model.train()
    losses = []
    for i in range(epochs):
        optimizer.zero_grad()

        # Forward pass
        y_pred = model(X_train)
        loss = criterion(y_pred, y_train)

        # Backward pass
        loss.backward()
        optimizer.step()

        losses.append(loss.item())
        if i % 10 == 0:
            print(f'Epoch: {i}, Loss: {loss.item():.4f}')

    # Make predictions
    model.eval()
    with torch.no_grad():
        test_predictions = model(X_test)

    # Inverse transform predictions and actual values
    test_predictions = test_predictions.numpy()
    test_predictions = scaler.inverse_transform(test_predictions)
    y_test_inv = scaler.inverse_transform(y_test)

    # Calculate metrics for each cryptocurrency
    metrics = {}
    for i, col in enumerate(coin_columns):
        metrics[col] = calculate_metrics(y_test_inv[:, i], test_predictions[:, i])

    # Plot LSTM predictions with actual values
    plt.figure(figsize=(15, 12))
    for i, col in enumerate(coin_columns):
        plt.subplot(3, 1, i+1)
        plt.plot(y_test_inv[:, i], label='Actual', color='blue', alpha=0.7)
        plt.plot(test_predictions[:, i], label='Predicted', color='red', alpha=0.7)
        plt.title(f'LSTM Predictions vs Actual for {col}')
        plt.xlabel('Time Steps')
        plt.ylabel('Price')

        # Add metrics annotation
        metrics_text = '\n'.join([f'{k}: {v:.4f}' for k, v in metrics[col].items()])
        plt.annotate(metrics_text, xy=(0.02, 0.95), xycoords='axes fraction',
                    bbox=dict(facecolor='white', alpha=0.8),
                    verticalalignment='top')

        plt.legend()
        plt.grid(True)
    plt.tight_layout()
    plt.savefig('/content/analysis_results/plots/lstm_predictions.png')
    plt.show()  # Display plot inline
    plt.close()

    return model, test_predictions, losses, metrics

def train_multivariate_prophet(price_data, timestamp_col, target_cols, forecast_days=30):
    """Train Prophet models for multiple cryptocurrencies"""
    models = {}
    forecasts = {}
    metrics = {}

    # Create subplot for all forecasts
    fig, axes = plt.subplots(len(target_cols), 1, figsize=(15, 5*len(target_cols)))

    for i, col in enumerate(target_cols):
        prophet_df = price_data[[timestamp_col, col]].rename(
            columns={timestamp_col: 'ds', col: 'y'}
        )

        # Split data for evaluation
        train_size = int(len(prophet_df) * 0.8)
        train_df = prophet_df[:train_size]
        test_df = prophet_df[train_size:]

        model = Prophet(daily_seasonality=True)
        model.fit(train_df)

        # Make predictions for test period
        test_dates = test_df['ds'].reset_index(drop=True)
        forecast = model.predict(pd.DataFrame({'ds': test_dates}))

        # Calculate metrics
        metrics[col] = calculate_metrics(test_df['y'].values, forecast['yhat'].values)

        # Future forecast
        future_dates = model.make_future_dataframe(periods=forecast_days)
        future_forecast = model.predict(future_dates)

        models[col] = model
        forecasts[col] = future_forecast

        # Plot forecast with metrics
        ax = axes[i]
        model.plot(future_forecast, ax=ax)
        ax.set_title(f'Prophet Forecast for {col}')

        # Add metrics annotation
        metrics_text = '\n'.join([f'{k}: {v:.4f}' for k, v in metrics[col].items()])
        ax.annotate(metrics_text, xy=(0.02, 0.95), xycoords='axes fraction',
                   bbox=dict(facecolor='white', alpha=0.8),
                   verticalalignment='top')

        ax.grid(True)

    plt.tight_layout()
    plt.savefig('/content/analysis_results/plots/prophet_forecasts_comparison.png')
    plt.show()  # Display plot inline
    plt.close()

    # Plot components for each cryptocurrency
    for col in target_cols:
        fig = models[col].plot_components(forecasts[col])
        plt.savefig(f'/content/analysis_results/plots/prophet_components_{col}.png')
        plt.show()  # Display plot inline
        plt.close()

    return models, forecasts, metrics

def analyze_price_correlations(price_data, coin_columns):
    """Analyze price correlations between cryptocurrencies"""
    # Calculate price correlations
    price_corr = price_data[coin_columns].corr()

    # Plot correlation heatmap
    plt.figure(figsize=(10, 8))
    sns.heatmap(price_corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1, fmt='.4f')
    plt.title('Price Correlation Heatmap')
    plt.savefig('/content/analysis_results/plots/price_correlation.png')
    plt.show()  # Display plot inline
    plt.close()

    return price_corr

def analyze_returns_volatility(returns_data, return_cols):
    """Analyze returns and volatility"""
    # Calculate rolling volatility
    window = 30
    volatility = pd.DataFrame(index=returns_data.index)
    for col in return_cols:
        volatility[f'{col}_vol'] = returns_data[col].rolling(window=window).std() * np.sqrt(252)

    # Plot volatility comparison
    plt.figure(figsize=(12, 6))
    for col in return_cols:
        plt.plot(volatility.index, volatility[f'{col}_vol'],
                label=col.split('_')[0].upper(), alpha=0.7)
    plt.title('30-Day Rolling Volatility')
    plt.xlabel('Date')
    plt.ylabel('Annualized Volatility')
    plt.legend()
    plt.grid(True)

    # Add summary statistics
    stats_text = []
    for col in return_cols:
        vol_stats = volatility[f'{col}_vol'].describe()
        stats_text.append(f"{col.split('_')[0].upper()}:\n" +
                         f"Mean: {vol_stats['mean']:.4f}\n" +
                         f"Max: {vol_stats['max']:.4f}\n" +
                         f"Min: {vol_stats['min']:.4f}")

    plt.annotate('\n\n'.join(stats_text), xy=(0.02, 0.95), xycoords='axes fraction',
                bbox=dict(facecolor='white', alpha=0.8),
                verticalalignment='top')

    plt.savefig('/content/analysis_results/plots/volatility_comparison.png')
    plt.show()  # Display plot inline
    plt.close()

    # Calculate and plot cumulative returns
    cumulative_returns = (1 + returns_data[return_cols]).cumprod()
    plt.figure(figsize=(12, 6))
    for col in return_cols:
        plt.plot(cumulative_returns.index, cumulative_returns[col],
                label=col.split('_')[0].upper(), alpha=0.7)
    plt.title('Cumulative Returns')
    plt.xlabel('Date')
    plt.ylabel('Cumulative Return')

    # Add summary statistics
    stats_text = []
    for col in return_cols:
        ret_stats = cumulative_returns[col].describe()
        final_return = cumulative_returns[col].iloc[-1]  # Get the last value
        stats_text.append(f"{col.split('_')[0].upper()}:\n" +
                         f"Final Return: {final_return:.4f}\n" +
                         f"Max: {ret_stats['max']:.4f}\n" +
                         f"Min: {ret_stats['min']:.4f}")

    plt.annotate('\n\n'.join(stats_text), xy=(0.02, 0.95), xycoords='axes fraction',
                bbox=dict(facecolor='white', alpha=0.8),
                verticalalignment='top')

    plt.legend()
    plt.grid(True)
    plt.savefig('/content/analysis_results/plots/cumulative_returns.png')
    plt.show()  # Display plot inline
    plt.close()

    return volatility

def print_evaluation_metrics(lstm_metrics, prophet_metrics):
    """Print detailed evaluation metrics for all models"""
    print("\nModel Evaluation Metrics:")
    print("\nLSTM Model Metrics:")
    for coin in lstm_metrics:
        print(f"\n{coin}:")
        for metric, value in lstm_metrics[coin].items():
            print(f"{metric}: {value:.4f}")

    print("\nProphet Model Metrics:")
    for coin in prophet_metrics:
        print(f"\n{coin}:")
        for metric, value in prophet_metrics[coin].items():
            print(f"{metric}: {value:.4f}")

def plot_model_comparison(lstm_metrics, prophet_metrics):
    """Create comparative plots of model performance metrics"""
    metrics_to_plot = ['RMSE', 'MAE', 'R2', 'MAPE']
    coins = list(lstm_metrics.keys())

    # Create subplots for each metric
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    axes = axes.flatten()

    for idx, metric in enumerate(metrics_to_plot):
        # Prepare data for plotting
        lstm_values = [lstm_metrics[coin][metric] for coin in coins]
        prophet_values = [prophet_metrics[coin][metric] for coin in coins]

        # Set up bar positions
        x = np.arange(len(coins))
        width = 0.35

        # Create grouped bar plot
        ax = axes[idx]
        ax.bar(x - width/2, lstm_values, width, label='LSTM', alpha=0.8)
        ax.bar(x + width/2, prophet_values, width, label='Prophet', alpha=0.8)

        # Customize plot
        ax.set_title(f'{metric} Comparison')
        ax.set_xticks(x)
        ax.set_xticklabels([coin.split('_')[0].upper() for coin in coins])
        ax.legend()
        ax.grid(True, alpha=0.3)

        # Add value labels on bars
        for i, v in enumerate(lstm_values):
            ax.text(i - width/2, v, f'{v:.2f}', ha='center', va='bottom')
        for i, v in enumerate(prophet_values):
            ax.text(i + width/2, v, f'{v:.2f}', ha='center', va='bottom')

    plt.tight_layout()
    plt.savefig('/content/analysis_results/plots/model_comparison.png')
    plt.show()  # Display plot inline
    plt.close()

def plot_training_progress(losses):
    """Plot LSTM training progress"""
    plt.figure(figsize=(10, 6))
    plt.plot(losses, label='Training Loss')
    plt.title('LSTM Training Progress')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.grid(True)
    plt.legend()

    # Add annotations for initial and final loss
    plt.annotate(f'Initial Loss: {losses[0]:.4f}',
                xy=(0, losses[0]),
                xytext=(10, losses[0]),
                arrowprops=dict(facecolor='black', shrink=0.05))
    plt.annotate(f'Final Loss: {losses[-1]:.4f}',
                xy=(len(losses)-1, losses[-1]),
                xytext=(len(losses)-20, losses[-1]*2),
                arrowprops=dict(facecolor='black', shrink=0.05))

    plt.savefig('/content/analysis_results/plots/lstm_training_progress.png')
    plt.show()  # Display plot inline
    plt.close()

def main():
    """Run the complete analysis pipeline"""
    print("Configuring plot display settings...")
    # Force plots to be shown inline in Colab
    from IPython import display
    display.set_matplotlib_formats('retina')

    print("Starting cryptocurrency analysis pipeline...")

    try:
        # Install required packages
        print("\nInstalling required packages...")
        os.system('pip install prophet torch seaborn scikit-learn')

        # Load data
        print("\nLoading data...")
        price_volume_df, returns_df, technical_df = load_data()
        if price_volume_df is None:
            raise ValueError("Failed to load data files")

        print(f"Loaded data shapes:")
        print(f"Price/Volume data: {price_volume_df.shape}")
        print(f"Returns data: {returns_df.shape}")
        print(f"Technical data: {technical_df.shape}")

        # Define cryptocurrency columns
        price_cols = ['btc_price', 'eth_price', 'sol_price']
        return_cols = ['btc_return', 'eth_return', 'sol_return']

        # Time Series Analysis
        print("\nRunning multivariate time series analysis...")

        # LSTM
        print("\nTraining multivariate LSTM model...")
        lstm_model, lstm_predictions, lstm_losses, lstm_metrics = train_multivariate_lstm(
            price_volume_df, price_cols
        )
        print(f"LSTM training complete. Final loss: {lstm_losses[-1]:.6f}")

        # Plot LSTM training progress
        plot_training_progress(lstm_losses)

        # Prophet
        print("\nTraining Prophet models...")
        prophet_models, prophet_forecasts, prophet_metrics = train_multivariate_prophet(
            price_volume_df, 'timestamp', price_cols
        )
        print("Prophet models training complete")

        # Print evaluation metrics
        print_evaluation_metrics(lstm_metrics, prophet_metrics)

        # Plot model comparison
        plot_model_comparison(lstm_metrics, prophet_metrics)

        # Price Correlation Analysis
        print("\nAnalyzing price correlations...")
        price_corr = analyze_price_correlations(price_volume_df, price_cols)
        print("Price correlation analysis complete")

        # Returns and Volatility Analysis
        print("\nAnalyzing returns and volatility...")
        volatility = analyze_returns_volatility(returns_df, return_cols)
        print("Returns and volatility analysis complete")

        # Save results
        results = {
            'lstm_metrics': lstm_metrics,
            'prophet_metrics': prophet_metrics,
            'price_correlations': price_corr.to_dict(),
            'model_evaluation': {
                'lstm_test_predictions_shape': lstm_predictions.shape,
                'prophet_forecast_periods': len(prophet_forecasts[price_cols[0]]),
                'lstm_final_loss': lstm_losses[-1]
            }
        }

        with open('/content/analysis_results/data/analysis_results.json', 'w') as f:
            json.dump(results, f, indent=4)

        print("\nAnalysis complete! Results have been saved to /content/analysis_results/")
        print("\nSummary of generated files:")
        print("1. LSTM predictions plot (with metrics)")
        print("2. LSTM training progress plot")
        print("3. Model comparison plots")
        print("4. Prophet forecasts comparison plot (with metrics)")
        print("5. Prophet components plots")
        print("6. Price correlation heatmap")
        print("7. Volatility comparison plot (with statistics)")
        print("8. Cumulative returns plot (with statistics)")
        print("9. Analysis results JSON file")

        # Print key findings
        print("\nKey Findings:")
        print("1. Model Performance:")
        for coin in lstm_metrics:
            print(f"\n{coin}:")
            print(f"  LSTM MAPE: {lstm_metrics[coin]['MAPE']:.2f}%")
            print(f"  Prophet MAPE: {prophet_metrics[coin]['MAPE']:.2f}%")
            print(f"  LSTM R2: {lstm_metrics[coin]['R2']:.4f}")
            print(f"  Prophet R2: {prophet_metrics[coin]['R2']:.4f}")

        print("\n2. Training Progress:")
        print(f"  Initial LSTM Loss: {lstm_losses[0]:.4f}")
        print(f"  Final LSTM Loss: {lstm_losses[-1]:.4f}")
        print(f"  Loss Improvement: {((lstm_losses[0] - lstm_losses[-1]) / lstm_losses[0] * 100):.2f}%")

    except Exception as e:
        print(f"\nError in analysis pipeline: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

    return True

if __name__ == "__main__":
    main()